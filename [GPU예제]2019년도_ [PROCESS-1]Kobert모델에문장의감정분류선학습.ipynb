{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14717,"status":"ok","timestamp":1661273138887,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"mk1ySC1o9LND","outputId":"3504f4be-c0d8-4f76-9a48-11e08a115596"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 34.3 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.1.0\n","  Downloading huggingface_hub-0.9.0-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 78.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,\u003c0.13,\u003e=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 69.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.1.0-\u003etransformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-\u003etransformers) (3.8.1)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2022.6.15)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003etransformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.0 tokenizers-0.12.1 transformers-4.21.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 38.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxxMdlB4afUP"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"7HhAqjLaSnY9"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"JpVJqpow9pPc"},"source":["#목차\n","가장 처음 학습은 주가 타이틀이나 기사컨텐츠를 보고 긍정적인 문장인지, 부정적인 문장인지 분류할 수 있도록 구어체로 감정표현이 많이 드러난 문장들을 대상으로 경연Bert모델에 긍/부정 감정을 풍부하게 만듭니다. \n","\u003cb\u003e1) 네이버 감성분석 데이터 불러오기 및 전처리 \n","2) BERT 인풋 만들기 \n","3) 버트를 활용한 감성분석 모델 만들기 \n","4) 훈련 및 성능 검증 \n","5) 실제 데이터로 테스트해보기\n","6) 감정이 학습된 Bert Model Weight 파일로 저장( 추후, 기사 타이틀 학습의 사전 모델로 사용됨) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4RJ6d5K_OmRq"},"outputs":[],"source":["DOC_PATH = '/content/drive/My Drive/Colab Notebooks/hyeonsang/'  ##colab 기준으로 작성했습니다. /content/drive/My Drive/Colab Notebooks/hyeonsang/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aq2k3bzZ9LNL"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from transformers import *\n","import json\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import os\n","import logging\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import optimizers\n","tf.get_logger().setLevel(logging.ERROR)\n","logging.basicConfig(level=logging.ERROR)\n","import sentencepiece as spm"]},{"cell_type":"markdown","metadata":{"id":"NrV4EUeN-f3N"},"source":["## 구글드라이브 연동"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25295,"status":"ok","timestamp":1661273174189,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"ETF5r7Tk-hxP","outputId":"90a40ce7-545e-4ad5-b779-ecc0a56eb22b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"17q-XSjD-pUQ"},"source":["## 네이버 영화 감성분석 데이터를 github에서 다운\n","- Train data : 150000 \n","- Test data : 50000\n","- All reviews are shorter than 140 characters\n","- Each sentiment class is sampled equally (i.e., random guess yields 50% accuracy)\n","-- 100K negative reviews (originally reviews of ratings 1-4)\n","-- 100K positive reviews (originally reviews of ratings 9-10)\n","-- Neutral reviews (originally reviews of ratings 5-8) are excluded"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7276,"status":"ok","timestamp":1661273181457,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"L20MbPqm9LNP","outputId":"f42adf94-6ac2-4300-fdb9-f2d66953a70f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 12.74 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"]}],"source":["!git clone https://github.com/e9t/nsmc.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGsXm_rG9LNU"},"outputs":[],"source":["os.listdir('nsmc')\n","G_SEQ_LEN = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V5ix8PA79LNZ"},"outputs":[],"source":["train = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\n","test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661273182187,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"hQwzUvv49LNf","outputId":"24f83736-f7a3-41c3-da4f-7294eea39585"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-1dc6e021-821f-49dc-b24a-03f53cbcf143\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003edocument\u003c/th\u003e\n","      \u003cth\u003elabel\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e50\u003c/th\u003e\n","      \u003ctd\u003e9063648\u003c/td\u003e\n","      \u003ctd\u003e영화가 사람의 영혼을 어루만져 줄 수도 있군요 거친 세상사를 잠시 잊고 동화같은 영...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e51\u003c/th\u003e\n","      \u003ctd\u003e8272095\u003c/td\u003e\n","      \u003ctd\u003e야 세르게이! 작은고추의 매운맛을 보여주마! 포퐁저그 콩진호가 간다\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e52\u003c/th\u003e\n","      \u003ctd\u003e2345905\u003c/td\u003e\n","      \u003ctd\u003e이렇게 가슴시리게 본 드라마가 또 있을까? 감동 그 자체!\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e53\u003c/th\u003e\n","      \u003ctd\u003e7865630\u003c/td\u003e\n","      \u003ctd\u003e난또 저 꼬마애가 무슨 원한이 깊길래.,. 했더니 OO 그냥 혼자 나대다 OO걸 어...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e54\u003c/th\u003e\n","      \u003ctd\u003e7207064\u003c/td\u003e\n","      \u003ctd\u003e재미있어요\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e55\u003c/th\u003e\n","      \u003ctd\u003e5719655\u003c/td\u003e\n","      \u003ctd\u003e전 좋아요\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e56\u003c/th\u003e\n","      \u003ctd\u003e1651126\u003c/td\u003e\n","      \u003ctd\u003e최고\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e57\u003c/th\u003e\n","      \u003ctd\u003e7246040\u003c/td\u003e\n","      \u003ctd\u003e너무 충격적이엇다. 기분을 완전히 푹 꺼지게 하는 느낌... 활력이라고는 하나도 없...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e58\u003c/th\u003e\n","      \u003ctd\u003e717775\u003c/td\u003e\n","      \u003ctd\u003e심심한영화.\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e59\u003c/th\u003e\n","      \u003ctd\u003e8317483\u003c/td\u003e\n","      \u003ctd\u003e백봉기 언제나오나요?\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e60\u003c/th\u003e\n","      \u003ctd\u003e1031725\u003c/td\u003e\n","      \u003ctd\u003e보는내내 그대로 들어맞는 예측 카리스마 없는 악역\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e61\u003c/th\u003e\n","      \u003ctd\u003e3993146\u003c/td\u003e\n","      \u003ctd\u003e불알이 나와서 당황...아무튼 영화가 중간에 끝나는 느낌\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e62\u003c/th\u003e\n","      \u003ctd\u003e2196616\u003c/td\u003e\n","      \u003ctd\u003e평범함속에 녹아든 평범한 일상. 조금 밋밋한게 흠.\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e63\u003c/th\u003e\n","      \u003ctd\u003e8203798\u003c/td\u003e\n","      \u003ctd\u003e보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e64\u003c/th\u003e\n","      \u003ctd\u003e2332588\u003c/td\u003e\n","      \u003ctd\u003e사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e65\u003c/th\u003e\n","      \u003ctd\u003e10084753\u003c/td\u003e\n","      \u003ctd\u003e많은 사람들이 이 다큐를 보고 우리나라 슬픈 현대사의 한 단면에 대해 깊이 생각하고...\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e66\u003c/th\u003e\n","      \u003ctd\u003e8518645\u003c/td\u003e\n","      \u003ctd\u003e예전 작품 캐릭터, 에피소드 재탕 삼탕 사골우려먹듯 우리고 내용은 산으로 가고 시청...\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e67\u003c/th\u003e\n","      \u003ctd\u003e7956793\u003c/td\u003e\n","      \u003ctd\u003e김남길의 백점짜리 연기력과 초반 몰입도에도 불구하고 지루하고 손예진 ㅈㅈ\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e68\u003c/th\u003e\n","      \u003ctd\u003e3996917\u003c/td\u003e\n","      \u003ctd\u003e재밌네 비슷한 영화를 안보신 분들한테는 재미있을 듯\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e69\u003c/th\u003e\n","      \u003ctd\u003e8128006\u003c/td\u003e\n","      \u003ctd\u003e노래실력으로뽑는게 맞냐? 박시환이 mama나가면 진짜 망신이다\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dc6e021-821f-49dc-b24a-03f53cbcf143')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-1dc6e021-821f-49dc-b24a-03f53cbcf143 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1dc6e021-821f-49dc-b24a-03f53cbcf143');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["          id                                           document  label\n","50   9063648  영화가 사람의 영혼을 어루만져 줄 수도 있군요 거친 세상사를 잠시 잊고 동화같은 영...      1\n","51   8272095              야 세르게이! 작은고추의 매운맛을 보여주마! 포퐁저그 콩진호가 간다      0\n","52   2345905                   이렇게 가슴시리게 본 드라마가 또 있을까? 감동 그 자체!      1\n","53   7865630  난또 저 꼬마애가 무슨 원한이 깊길래.,. 했더니 OO 그냥 혼자 나대다 OO걸 어...      0\n","54   7207064                                              재미있어요      1\n","55   5719655                                              전 좋아요      1\n","56   1651126                                                 최고      0\n","57   7246040  너무 충격적이엇다. 기분을 완전히 푹 꺼지게 하는 느낌... 활력이라고는 하나도 없...      1\n","58    717775                                             심심한영화.      0\n","59   8317483                                        백봉기 언제나오나요?      1\n","60   1031725                        보는내내 그대로 들어맞는 예측 카리스마 없는 악역      0\n","61   3993146                    불알이 나와서 당황...아무튼 영화가 중간에 끝나는 느낌      0\n","62   2196616                       평범함속에 녹아든 평범한 일상. 조금 밋밋한게 흠.      0\n","63   8203798  보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에...      0\n","64   2332588                     사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.      1\n","65  10084753  많은 사람들이 이 다큐를 보고 우리나라 슬픈 현대사의 한 단면에 대해 깊이 생각하고...      1\n","66   8518645  예전 작품 캐릭터, 에피소드 재탕 삼탕 사골우려먹듯 우리고 내용은 산으로 가고 시청...      0\n","67   7956793           김남길의 백점짜리 연기력과 초반 몰입도에도 불구하고 지루하고 손예진 ㅈㅈ      0\n","68   3996917                       재밌네 비슷한 영화를 안보신 분들한테는 재미있을 듯      1\n","69   8128006                 노래실력으로뽑는게 맞냐? 박시환이 mama나가면 진짜 망신이다      0"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train[50:70]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgTJF7uK9LNl"},"outputs":[],"source":["#코버트간다. \n","import logging\n","import os\n","import unicodedata\n","from shutil import copyfile\n","\n","from transformers import PreTrainedTokenizer\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n","                     \"vocab_txt\": \"vocab.txt\"}\n","\n","PRETRAINED_VOCAB_FILES_MAP = {\n","    \"vocab_file\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n","    },\n","    \"vocab_txt\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n","    }\n","}\n","\n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n","    \"monologg/kobert\": 512,\n","    \"monologg/kobert-lm\": 512,\n","    \"monologg/distilkobert\": 512\n","}\n","\n","PRETRAINED_INIT_CONFIGURATION = {\n","    \"monologg/kobert\": {\"do_lower_case\": False},\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\n","}\n","\n","SPIECE_UNDERLINE = u'▁'\n","\n","\n","class KoBertTokenizer(PreTrainedTokenizer):\n","    \"\"\"\n","        SentencePiece based tokenizer. Peculiarities:\n","            - requires `SentencePiece \u003chttps://github.com/google/sentencepiece\u003e`_\n","    \"\"\"\n","    vocab_files_names = VOCAB_FILES_NAMES\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n","\n","    def __init__(\n","            self,\n","            vocab_file,\n","            vocab_txt,\n","            do_lower_case=False,\n","            remove_space=True,\n","            keep_accents=False,\n","            unk_token=\"[UNK]\",\n","            sep_token=\"[SEP]\",\n","            pad_token=\"[PAD]\",\n","            cls_token=\"[CLS]\",\n","            mask_token=\"[MASK]\",\n","            **kwargs):\n","        super().__init__(\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            pad_token=pad_token,\n","            cls_token=cls_token,\n","            mask_token=mask_token,\n","            **kwargs\n","        )\n","\n","        # Build vocab\n","        self.token2idx = dict()\n","        self.idx2token = []\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\n","            for idx, token in enumerate(f):\n","                token = token.strip()\n","                self.token2idx[token] = idx\n","                self.idx2token.append(token)\n","\n","        #self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n","        #self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n","\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","\n","        self.do_lower_case = do_lower_case\n","        self.remove_space = remove_space\n","        self.keep_accents = keep_accents\n","        self.vocab_file = vocab_file\n","        self.vocab_txt = vocab_txt\n","\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n","\n","    @property\n","    def vocab_size(self):\n","        return len(self.idx2token)\n","\n","    def __getstate__(self):\n","        state = self.__dict__.copy()\n","        state[\"sp_model\"] = None\n","        return state\n","\n","    def __setstate__(self, d):\n","        self.__dict__ = d\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(self.vocab_file)\n","\n","    def preprocess_text(self, inputs):\n","        if self.remove_space:\n","            outputs = \" \".join(inputs.strip().split())\n","        else:\n","            outputs = inputs\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n","\n","        if not self.keep_accents:\n","            outputs = unicodedata.normalize('NFKD', outputs)\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n","        if self.do_lower_case:\n","            outputs = outputs.lower()\n","\n","        return outputs\n","\n","    def _tokenize(self, text, return_unicode=True, sample=False):\n","        \"\"\" Tokenize a string. \"\"\"\n","        text = self.preprocess_text(text)\n","\n","        if not sample:\n","            pieces = self.sp_model.EncodeAsPieces(text)\n","        else:\n","            #pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, G_SEQ_LEN, 0)\n","        new_pieces = []\n","        for piece in pieces:\n","            if len(piece) \u003e 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n","                    if len(cur_pieces[0]) == 1:\n","                        cur_pieces = cur_pieces[1:]\n","                    else:\n","                        cur_pieces[0] = cur_pieces[0][1:]\n","                cur_pieces.append(piece[-1])\n","                new_pieces.extend(cur_pieces)\n","            else:\n","                new_pieces.append(piece)\n","\n","        return new_pieces\n","\n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\n","\n","    def _convert_id_to_token(self, index, return_unicode=True):\n","        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n","        return self.idx2token[index]\n","\n","    def convert_tokens_to_string(self, tokens):\n","        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n","        return out_string\n","\n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n","        by concatenating and adding special tokens.\n","        A RoBERTa sequence has the following format:\n","            single sequence: [CLS] X [SEP]\n","            pair of sequences: [CLS] A [SEP] B [SEP]\n","        \"\"\"\n","        if token_ids_1 is None:\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        sep = [self.sep_token_id]\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\n","\n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n","        \"\"\"\n","        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n","        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n","        Args:\n","            token_ids_0: list of ids (must not contain special tokens)\n","            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n","                for sequence pairs\n","            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n","                special tokens for the model\n","        Returns:\n","            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n","        \"\"\"\n","\n","        if already_has_special_tokens:\n","            if token_ids_1 is not None:\n","                raise ValueError(\n","                    \"You should not supply a second sequence if the provided sequence of \"\n","                    \"ids is already formated with special tokens for the model.\"\n","                )\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n","\n","        if token_ids_1 is not None:\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n","        return [1] + ([0] * len(token_ids_0)) + [1]\n","\n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n","        A BERT sequence pair mask has the following format:\n","        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n","        | first sequence    | second sequence\n","        if token_ids_1 is None, only returns the first portion of the mask (0's).\n","        \"\"\"\n","        sep = [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        if token_ids_1 is None:\n","            return len(cls + token_ids_0 + sep) * [0]\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n","\n","    def save_vocabulary(self, save_directory):\n","        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n","            to a directory.\n","        \"\"\"\n","        if not os.path.isdir(save_directory):\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n","            return\n","\n","        # 1. Save sentencepiece model\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n","\n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n","            copyfile(self.vocab_file, out_vocab_model)\n","\n","        # 2. Save vocab.txt\n","        index = 0\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n","                if index != token_index:\n","                    logger.warning(\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n","                    )\n","                    index = token_index\n","                writer.write(token + \"\\n\")\n","                index += 1\n","\n","        return out_vocab_model, out_vocab_txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12083,"status":"ok","timestamp":1661273194266,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"emrsFw0p9LNr","outputId":"15ae25d7-2a6c-46fd-a5f8-2cd37da95753"},"outputs":[{"name":"stderr","output_type":"stream","text":["https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tokenizer_78b3253a26.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp9nsl2pi0\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcc0301a22a34ebfa30c3cf46025e819","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_78b3253a26.model:   0%|          | 0.00/363k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tokenizer_78b3253a26.model in cache at /root/.cache/huggingface/transformers/43bbee2de615a89368e6f67ad57d91bf62b36f0347dd2b4a099b47dab6effec7.3298791184927769289badb2a4fa1a4e2c58e4b032da9b4d3d29faeb2e5b0cda\n","creating metadata file for /root/.cache/huggingface/transformers/43bbee2de615a89368e6f67ad57d91bf62b36f0347dd2b4a099b47dab6effec7.3298791184927769289badb2a4fa1a4e2c58e4b032da9b4d3d29faeb2e5b0cda\n","https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp5_lie9vs\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29a78b25cfa1454ba4589b299499878c","version_major":2,"version_minor":0},"text/plain":["Downloading vocab.txt:   0%|          | 0.00/68.1k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/0a97c0f685d07f9fa4ee7968a2c802a156f1b82d1c2b44c81ebf5a8e49a65d6a.9cad641b304b5ad278af344eb08848d342da168ced6ad4f5fbb38486b3410e86\n","creating metadata file for /root/.cache/huggingface/transformers/0a97c0f685d07f9fa4ee7968a2c802a156f1b82d1c2b44c81ebf5a8e49a65d6a.9cad641b304b5ad278af344eb08848d342da168ced6ad4f5fbb38486b3410e86\n","https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnx8qilzm\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f1301c452f34a509764d94b7caff945","version_major":2,"version_minor":0},"text/plain":["Downloading special_tokens_map.json:   0%|          | 0.00/112 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/3a6d42dde7a5003d2fa07279c0733d3b4c9be8f093fd649a275f037885e5778b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","creating metadata file for /root/.cache/huggingface/transformers/3a6d42dde7a5003d2fa07279c0733d3b4c9be8f093fd649a275f037885e5778b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpsx07ks70\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd9c174d4eb14487a5bcfcb4ae6a5100","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/245 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/de228ccdeeeb95c5e8fd03d3b52de4390ce93a531d11076ca673c0bce49e3c7e.d041aee5e462fc23a0c0c950e5022a0036d097d607dca1432a41c996f34f10d8\n","creating metadata file for /root/.cache/huggingface/transformers/de228ccdeeeb95c5e8fd03d3b52de4390ce93a531d11076ca673c0bce49e3c7e.d041aee5e462fc23a0c0c950e5022a0036d097d607dca1432a41c996f34f10d8\n","loading file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/transformers/43bbee2de615a89368e6f67ad57d91bf62b36f0347dd2b4a099b47dab6effec7.3298791184927769289badb2a4fa1a4e2c58e4b032da9b4d3d29faeb2e5b0cda\n","loading file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0a97c0f685d07f9fa4ee7968a2c802a156f1b82d1c2b44c81ebf5a8e49a65d6a.9cad641b304b5ad278af344eb08848d342da168ced6ad4f5fbb38486b3410e86\n","loading file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/3a6d42dde7a5003d2fa07279c0733d3b4c9be8f093fd649a275f037885e5778b.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n","loading file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/de228ccdeeeb95c5e8fd03d3b52de4390ce93a531d11076ca673c0bce49e3c7e.d041aee5e462fc23a0c0c950e5022a0036d097d607dca1432a41c996f34f10d8\n","https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvmtizlyk\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af0f3ff5a21c430ba02184d269e01260","version_major":2,"version_minor":0},"text/plain":["Downloading config.json:   0%|          | 0.00/596 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/2e4d8b8998ae5495745c8f58870dbb268ad954a9517f4d35f835b78453df6c65.0d9d6237228c60750b87bf4651a0e16d2102c4181827c2cfe1291860903d9a98\n","creating metadata file for /root/.cache/huggingface/transformers/2e4d8b8998ae5495745c8f58870dbb268ad954a9517f4d35f835b78453df6c65.0d9d6237228c60750b87bf4651a0e16d2102c4181827c2cfe1291860903d9a98\n","loading configuration file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2e4d8b8998ae5495745c8f58870dbb268ad954a9517f4d35f835b78453df6c65.0d9d6237228c60750b87bf4651a0e16d2102c4181827c2cfe1291860903d9a98\n","Model config BertConfig {\n","  \"_name_or_path\": \"HyeonSang/kobert-sentiment\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 8002\n","}\n","\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'KoBertTokenizer'.\n"]}],"source":["#!pip install ipywidgets\n","#!jupyter nbextension enable --py widgetsnbextension\n","#tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n","tokenizer = KoBertTokenizer.from_pretrained('HyeonSang/kobert-sentiment')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1661273194266,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"gLrryG_Y9LN4","outputId":"e6bbd553-4485-4ffd-d0f3-2a37e40154b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["['▁전', '율을', '▁일으키', '는', '▁영화', '.', '▁다시', '▁보고', '싶', '은', '▁영화']\n"]}],"source":["print(tokenizer.tokenize(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1661273194266,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"IcHh7VOL9LN8","outputId":"bb51b4ce-cdd7-4294-eca4-4c861a95fcf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3]\n"]}],"source":["print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661273194266,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"34PzVhmK9LOA","outputId":"414c93ed-386c-46a6-f545-fc7d3cacaa78"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\", max_length=G_SEQ_LEN, pad_to_max_length=True, truncation=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1661273194267,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"A4uwMk-R9LOE","outputId":"9a82c7d4-e8d3-43a2-a580-d75e102e2b4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["# 세그멘트 인풋\n","print([0]*G_SEQ_LEN)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1661273194267,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"pI3XdYtI9LOH","outputId":"fa295ef6-27ff-4500-8175-3d4387fae3d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["# 마스크 인풋\n","valid_num = len(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))\n","print(valid_num * [1] + (G_SEQ_LEN - valid_num) * [0])"]},{"cell_type":"markdown","metadata":{"id":"Fm8RrnWXBQzO"},"source":["# 활용함수는 아래 정의"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fW819g6I9LOJ"},"outputs":[],"source":["def convert_data(data_df):\n","    global tokenizer\n","    \n","    SEQ_LEN = G_SEQ_LEN #SEQ_LEN : 버트에 들어갈 인풋의 길이\n","    \n","    tokens, masks, segments, targets = [], [], [], []\n","    \n","    for i in tqdm(range(len(data_df))):\n","        # token : 문장을 토큰화함\n","        #token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\n","        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True, truncation=True)\n","       \n","        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n","        num_zeros = token.count(0)\n","        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n","        \n","        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\n","        segment = [0]*SEQ_LEN\n","\n","        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n","        tokens.append(token)\n","        masks.append(mask)\n","        segments.append(segment)\n","        \n","        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장해 줌\n","        targets.append(data_df[LABEL_COLUMN][i])\n","\n","    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    targets = np.array(targets)\n","\n","    return [tokens, masks, segments], targets\n","\n","# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n","def load_data(pandas_dataframe):\n","    data_df = pandas_dataframe\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n","    data_x, data_y = convert_data(data_df)\n","    return data_x, data_y\n","    \n","def dfJHSSentanceInspect(_column):\n","    list = _column.tolist()\n","    tokenized_list = [r.split() for r in list]\n","    sentence_len_by_token = [len(t) for t in tokenized_list]\n","    sentence_len_by_eumjeol = [len(s.replace(' ', '')) for s in list]\n","    \n","    plt.figure(figsize = (12,5)) \n","    plt.hist(sentence_len_by_token, bins = 50, alpha=0.5, color=\"r\", label=\"word\") \n","    plt.hist(sentence_len_by_eumjeol, bins = 50, alpha=0.5, color=\"b\", label=\"aplt.yscallphabet\") \n","    plt.yscale('log', nonposy = 'clip') \n","    plt.title(_column.name) \n","    plt.xlabel('red:token / blue:eumjeol length') \n","    plt.ylabel('number of sentences')\n","\n","    \n","    print('\\n', ) \n","    print('칼럼명 : {}'.format(_column.name)) \n","    print('토큰 최대 길이 : {}'.format(np.max(sentence_len_by_token))) \n","    print('토큰 최소 길이 : {}'.format(np.min(sentence_len_by_token))) \n","    print('토큰 평균 길이 : {:.2f}'.format(np.mean(sentence_len_by_token))) \n","    print('토큰 길이 표준편차 : {:.2f}'.format(np.std(sentence_len_by_token))) \n","    print('토큰 중간 길이 : {}'.format(np.median(sentence_len_by_token))) \n","    print('제 1사분위 길이 : {}'.format(np.percentile(sentence_len_by_token, 25))) \n","    print('제 3사분위 길이 : {}'.format(np.percentile(sentence_len_by_token, 75)))\n","    print('빨간색 히스토그램은 토큰 개수에 대한 히스토그램: EX\u003e 나는 아침밥을 먹었다 -\u003e 3 ')\n","    print('파란색 음절 개수의 히스토그램 EX\u003e 나는 아침밥을 먹었다-\u003e 9' )"]},{"cell_type":"markdown","metadata":{"id":"CGmmNol7BXDG"},"source":["# train의 문장 분포를 검사합니다. \n","- 경연에서 주어진 meta.dill과 비슷한 분포를 보이고 있어 transfer learning시 기사 문장에 잘 학습 fit할 것으로 보임"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"executionInfo":{"elapsed":1668,"status":"ok","timestamp":1661273195931,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"EMVH6c6_Bm8m","outputId":"8bec4fbb-49b0-4e18-e7ac-70469a3fe49a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of Series.dropna will be keyword-only\n","  \"\"\"Entry point for launching an IPython kernel.\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","칼럼명 : document\n","토큰 최대 길이 : 41\n","토큰 최소 길이 : 1\n","토큰 평균 길이 : 7.59\n","토큰 길이 표준편차 : 6.51\n","토큰 중간 길이 : 6.0\n","제 1사분위 길이 : 3.0\n","제 3사분위 길이 : 9.0\n","빨간색 히스토그램은 토큰 개수에 대한 히스토그램: EX\u003e 나는 아침밥을 먹었다 -\u003e 3 \n","파란색 음절 개수의 히스토그램 EX\u003e 나는 아침밥을 먹었다-\u003e 9\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 864x360 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["dfJHSSentanceInspect(train.document.dropna(''))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1661273195932,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"5wslW06G_hwP","outputId":"42c8dd45-5aff-4709-fc51-5abeb00bf13d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(150000, 3)\n","(50000, 3)\n"]}],"source":["print(train.shape)\n","print(test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63pdyDZc_cjz"},"outputs":[],"source":["SEQ_LEN = G_SEQ_LEN\n","BATCH_SIZE = 32\n","# 긍부정 문장을 포함하고 있는 칼럼\n","DATA_COLUMN = \"document\"\n","# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\n","LABEL_COLUMN = \"label\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45432,"status":"ok","timestamp":1661273241357,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"uEJl-FsO9LOM","outputId":"1408c046-4fc5-4bd7-86a2-fd97be203466"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 150000/150000 [00:31\u003c00:00, 4723.24it/s]\n","100%|██████████| 50000/50000 [00:11\u003c00:00, 4488.05it/s]\n"]}],"source":["# train 데이터를 버트 인풋에 맞게 변환\n","#집보다 느린건 참을수가 없다. \n","train_x, train_y = load_data(train)\n","test_x, test_y = load_data(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vOQAD2O9LOO"},"outputs":[],"source":["#!pip install tensorflow_addons\n","#import tensorflow_addons as tfa\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1661273241358,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"ge1-b1dQ9LOS","outputId":"b12d2435-46c1-4737-cf88-7d1030e757ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 13874956236927762635\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14444920832\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 11926210150568102165\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]}],"source":["# GPU모드사용할때 이름 찾기 \n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"markdown","metadata":{"id":"JMcxErueA8WI"},"source":["# 모델생성\n","GPU모드 사용방법\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tH-h3ZPoB7a7"},"outputs":[],"source":["# TPU 객체 만들기\n","\n","#resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","#tf.config.experimental_connect_to_cluster(resolver)\n","#tf.tpu.experimental.initialize_tpu_system(resolver)"]},{"cell_type":"markdown","metadata":{"id":"lsuJTRbHDEZF"},"source":["### 모델생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBKUVjqC9LOU"},"outputs":[],"source":["def create_sentiment_bert():\n","    opt = optimizers.Adam(lr=5.0e-5,  epsilon=1e-08)        \n","    #model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n","    model = TFBertModel.from_pretrained(\"HyeonSang/kobert-sentiment\", from_pt=False)\n","    # 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n","    token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n","    mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n","    segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n","    # 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n","    bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n","    bert_outputs = bert_outputs[1]    \n","    \n","    sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n","    sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\n","    sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n","    sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n","    return sentiment_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"executionInfo":{"elapsed":34822,"status":"ok","timestamp":1661273276174,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"i8cmu11NC0N5","outputId":"d01047b3-4869-49ed-b177-ac19137729ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of devices: 1\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n","loading configuration file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2e4d8b8998ae5495745c8f58870dbb268ad954a9517f4d35f835b78453df6c65.0d9d6237228c60750b87bf4651a0e16d2102c4181827c2cfe1291860903d9a98\n","Model config BertConfig {\n","  \"_name_or_path\": \"monologg/kobert\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.21.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 8002\n","}\n","\n","https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tf_model.h5 not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp826se4pk\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3dc4594bf21415b9b0cc63e6474a238","version_major":2,"version_minor":0},"text/plain":["Downloading tf_model.h5:   0%|          | 0.00/352M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["storing https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tf_model.h5 in cache at /root/.cache/huggingface/transformers/54a224eebf5e5d2fb22916288b8ed5e7c859fffbcd8ecd764d271df63ee35336.6e8a00766d675a6d70d33d9f5119f242a66fb81279e7cc9d078e7866e46422d4.h5\n","creating metadata file for /root/.cache/huggingface/transformers/54a224eebf5e5d2fb22916288b8ed5e7c859fffbcd8ecd764d271df63ee35336.6e8a00766d675a6d70d33d9f5119f242a66fb81279e7cc9d078e7866e46422d4.h5\n","loading weights file https://huggingface.co/HyeonSang/kobert-sentiment/resolve/main/tf_model.h5 from cache at /root/.cache/huggingface/transformers/54a224eebf5e5d2fb22916288b8ed5e7c859fffbcd8ecd764d271df63ee35336.6e8a00766d675a6d70d33d9f5119f242a66fb81279e7cc9d078e7866e46422d4.h5\n","All model checkpoint layers were used when initializing TFBertModel.\n","\n","All the layers of TFBertModel were initialized from the model checkpoint at HyeonSang/kobert-sentiment.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}],"source":["strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"],cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) #GPU모드 \n","print('Number of devices: {}'.format(strategy.num_replicas_in_sync)) # GPU\n","#strategy = tf.distribute.experimental.TPUStrategy(resolver) # TPU모드 \n","with strategy.scope():\n","    sentiment_model = create_sentiment_bert() "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1661273276175,"user":{"displayName":"wingnut987S","userId":"08661693385076833574"},"user_tz":-540},"id":"9A4LrfMM9LOW","outputId":"b69be425-e25c-46fb-eea6-f0d7ff1c894b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 64)]         0           []                               \n","                                                                                                  \n"," input_masks (InputLayer)       [(None, 64)]         0           []                               \n","                                                                                                  \n"," input_segment (InputLayer)     [(None, 64)]         0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  92186880    ['input_word_ids[0][0]',         \n","                                thPoolingAndCrossAt               'input_masks[0][0]',            \n","                                tentions(last_hidde               'input_segment[0][0]']          \n","                                n_state=(None, 64,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 768)          0           ['tf_bert_model[0][1]']          \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            769         ['dropout_37[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 92,187,649\n","Trainable params: 92,187,649\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["sentiment_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uI1dTbuv9LOZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\n","2344/2344 [==============================] - 2119s 897ms/step - loss: 0.2756 - accuracy: 0.8866 - val_loss: 0.2600 - val_accuracy: 0.8942\n","Epoch 2/4\n","2344/2344 [==============================] - 2109s 900ms/step - loss: 0.2132 - accuracy: 0.9155 - val_loss: 0.2684 - val_accuracy: 0.8945\n","Epoch 3/4\n","2344/2344 [==============================] - 2107s 899ms/step - loss: 0.1650 - accuracy: 0.9373 - val_loss: 0.2876 - val_accuracy: 0.8943\n","Epoch 4/4\n","2344/2344 [==============================] - 2104s 898ms/step - loss: 0.1236 - accuracy: 0.9548 - val_loss: 0.3140 - val_accuracy: 0.8915\n"]}],"source":["hist = sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=64, validation_data=(test_x, test_y))\n","#hist=sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=120, validation_split=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vfCdLO2P9LOc"},"outputs":[],"source":["def predict_convert_data(data_df):\n","    global tokenizer\n","    tokens, masks, segments = [], [], []\n","    \n","    for i in tqdm(range(len(data_df))):\n","\n","        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\n","        num_zeros = token.count(0)\n","        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n","        segment = [0]*SEQ_LEN\n","\n","        tokens.append(token)\n","        segments.append(segment)\n","        masks.append(mask)\n","\n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    return [tokens, masks, segments]\n","\n","# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n","def predict_load_data(pandas_dataframe):\n","    data_df = pandas_dataframe\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","    data_x = predict_convert_data(data_df)\n","    return data_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0pMx4pM59LOf"},"outputs":[{"name":"stdout","output_type":"stream","text":["done\n"]}],"source":["print('done')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XW-omqDO9LOk"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/50000 [00:00\u003c?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","100%|██████████| 50000/50000 [00:10\u003c00:00, 4741.35it/s]\n"]}],"source":["test_set = predict_load_data(test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v0ZdnVfq9LOn"},"outputs":[{"data":{"text/plain":["[array([[   2,  517, 5515, ...,    1,    1,    1],\n","        [   2,  650,  278, ...,    1,    1,    1],\n","        [   2, 2145, 6844, ...,    1,    1,    1],\n","        ...,\n","        [   2, 1212, 5859, ...,    1,    1,    1],\n","        [   2, 4069, 2420, ...,    1,    1,    1],\n","        [   2, 1914, 5760, ...,    1,    1,    1]]),\n"," array([[1, 1, 1, ..., 1, 1, 1],\n","        [1, 1, 1, ..., 1, 1, 1],\n","        [1, 1, 1, ..., 1, 1, 1],\n","        ...,\n","        [1, 1, 1, ..., 1, 1, 1],\n","        [1, 1, 1, ..., 1, 1, 1],\n","        [1, 1, 1, ..., 1, 1, 1]]),\n"," array([[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]])]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["test_set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PdaFnm59LOu"},"outputs":[],"source":["preds = sentiment_model.predict(test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7KG8QVE59LOx"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.87      0.91      0.89     24827\n","           1       0.91      0.87      0.89     25173\n","\n","    accuracy                           0.89     50000\n","   macro avg       0.89      0.89      0.89     50000\n","weighted avg       0.89      0.89      0.89     50000\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","y_true = test['label']\n","# F1 Score 확인\n","print(classification_report(y_true, np.round(preds,0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7fVzrTIG9LOz"},"outputs":[],"source":["import logging\n","tf.get_logger().setLevel(logging.ERROR)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BfDT8t7r9LO1"},"outputs":[],"source":["def sentence_convert_data(data):\n","    global tokenizer\n","    tokens, masks, segments = [], [], []\n","    token = tokenizer.encode(data, max_length=SEQ_LEN, pad_to_max_length=True, truncation=True)\n","    \n","    num_zeros = token.count(0) \n","    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros \n","    segment = [0]*SEQ_LEN\n","\n","    tokens.append(token)\n","    segments.append(segment)\n","    masks.append(mask)\n","\n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    return [tokens, masks, segments]\n","\n","def movie_evaluation_predict(sentence):\n","    data_x = sentence_convert_data(sentence)\n","    predict = sentiment_model.predict(data_x)\n","    predict_value = np.ravel(predict)\n","    predict_answer = np.round(predict_value,0).item()\n","    \n","    if predict_answer == 0:\n","        print(\"(부정 확률 : %.2f) 부정적인 문장입니다.\" % (1-predict_value))\n","    elif predict_answer == 1:\n","        print(\"(긍정 확률 : %.2f) 긍정적인 문장입니다.\" % predict_value)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VAys4E4a9LO3"},"outputs":[{"name":"stdout","output_type":"stream","text":["(긍정 확률 : 1.00) 긍정적인 문장입니다.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"name":"stdout","output_type":"stream","text":["(긍정 확률 : 1.00) 긍정적인 문장입니다.\n"]}],"source":["#movie_evaluation_predict(\"보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에 \")\n","movie_evaluation_predict('사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.') #이건 학습데이터 찐긍정\n","movie_evaluation_predict('사랑을 했는데, 가슴이 웅장해져. 최고의 영화가 아닐까 한다.') #이건 학습데이터랑 비슷한 문장으로 \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VnFe97XY9LO8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(긍정 확률 : 0.80) 긍정적인 문장입니다.\n","(긍정 확률 : 0.92) 긍정적인 문장입니다.\n","(부정 확률 : 0.98) 부정적인 문장입니다.\n"]}],"source":["# . 내껀 센텐스 분류기다. \n","movie_evaluation_predict('가 새해 첫날 외국인 투자자와 기관투자자의 동반 매수세에 힘입어 3% 이상 상승했다.') \n","movie_evaluation_predict('장중 2만6650원까지 올랐다.') \n","movie_evaluation_predict('장중 2만6650원까지 하락했다.') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSkKBmyK9LO-"},"outputs":[],"source":["sentiment_model.output_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDAxhWMj9LPB"},"outputs":[],"source":["movie_evaluation_predict('2일 오후 12시40분 현재 뿅뿅주가는 전일대비 3.11% 오른 2만6550원에 거래 중이다.') "]},{"cell_type":"markdown","metadata":{"id":"_TbRHHWhPyft"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nevf2Q6N9LPD"},"outputs":[],"source":["movie_evaluation_predict('장중 2만6650원(3.5%)까지 올랐다.') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBBn9ZNP9LPF"},"outputs":[],"source":["movie_evaluation_predict('우리투자, CS, NH가 매수창구 상위에 이름을 올렸다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i2L9cbTO9LPI"},"outputs":[],"source":["movie_evaluation_predict('외국계 증권사 창구에서 9만주 이상 매수 우위를 나타냈다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VX0ShSLT9LPK"},"outputs":[],"source":["movie_evaluation_predict('이날 오전 11시 20분 기준 외국인과 기관은 SK하이닉스를 각각 18만3000주, 10만주씩 순매수한 것으로 잠정 집계됐다.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWHltSydxuZg"},"outputs":[],"source":["movie_evaluation_predict('최 연구원은 최근 하이닉스의 주가 변동성을 미·중 무역분쟁과 일본의 수출규제 조치 등 외부 변수에 의한 것으로 설명했다.')"]},{"cell_type":"markdown","metadata":{"id":"g01rv3dEQFQG"},"source":["### 문장을 테스트해보면 긍정적이라고 나오는 것 같지만, 감정을 추가한 모델을 이용하여 바로 모든 주가 기사 문장을 예측해보면 F1-score가 54%쯤 나왔습니다. \n","- 다음 프로세스에서는 meta.dill 기사 컨텐츠정도의 길이의 네이버 영화 평론 감정 문장을 학습시킨 Bert 모델을 기반으로 기사의 핵심 내용이 담긴 제목을 학습하겠습니다. \n","- 제목은 전달하고자 하는 주가 내용의 핵심이 담겨있고, 짧고 명료하게 구성되어 있으리라 가정합니다.\n","- 또한, 제목은 사람들의 시선을 끌기위한 감정이 섞인 (가슴이 웅장해지는) 문장으로 구성되어있으리라 가정합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYt5kJ839LPM"},"outputs":[],"source":["# accuracy 조회\n","# accuracy가 올라가고, validation_accuracy가 내려가는 오버피팅 구간이 있는지 확인한다. \n","plt.figure(figsize=(10,10))\n","plt.subplot(2, 2, 1)\n","plt.plot(hist.history['accuracy'], color='r')\n","plt.plot(hist.history['val_accuracy'], color='b')\n","plt.title('accuracy')\n","\n","#loss 조회\n","plt.subplot(2, 2, 2)\n","plt.plot(hist.history['loss'], color='r')\n","plt.plot(hist.history['val_loss'], color='b')\n","plt.title('loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GD5fwsfSgoT"},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","confusion_matrix(y_true, np.round(preds,0), labels=[1, 0]) #1과 0에 대한 CONFUSION_MATRIX"]},{"cell_type":"markdown","metadata":{"id":"nsps0AvxNl9N"},"source":["# 감정분류가 학습된 Bert model의 weight를 저장합니다. \n","- 저장한 모델의 감정 분류 node의 coefficients들은 두번째 Process인 기사 제목(Title)을 학습하는 PreTrained Model로써 사용합니다. \n","- 다음 작업은,  주가 기사의 타이틀을 학습하기 위해 경연에서 주어진 CSV파일을 이용하여, 기사 제목 데이터를 전처리하는 과정입니다. \n","- 파일은, [전처리-1]CSV파일의타이틀추출및클린징.ipynb 입니다"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKtZs0nH9LPP"},"outputs":[],"source":["file_name = os.path.join(DOC_PATH, 'result/transfer_model/gpu_2019_process1_emotional_base_model.h5')\n","sentiment_model.save_weights(file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miPWK0WHNQyd"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"[GPU예제]2019년도_ [PROCESS-1]Kobert모델에문장의감정분류선학습.ipynb","toc_visible":true,"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01360230d6494f7db959660fc7cfcbbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a565419bf9b43f095657e2f173dce62","placeholder":"​","style":"IPY_MODEL_fecf7a694b144afb80b5001e4056c139","value":"Downloading config.json: 100%"}},"073267495dec4b12b1884505b8a62dd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b02abca7f4f4728b67b6ec9ec3271d3","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_207d12a144fd4b27933a9a5b040e1b71","value":112}},"0851d922ebf74839be2e3983b52ed7a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb7cf85a1c764cc8b191824045d9801c","placeholder":"​","style":"IPY_MODEL_1e1af957f86e4cd4a8ef098d890ab271","value":" 363k/363k [00:00\u0026lt;00:00, 496kB/s]"}},"0dccde57f844447c83353d39c227e920":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eb88c11bc4c4efa86603cd847e45a90","placeholder":"​","style":"IPY_MODEL_c7df33d9d9cd4b30804fb735caac8aa7","value":" 68.1k/68.1k [00:00\u0026lt;00:00, 79.5kB/s]"}},"0df6ae9ad14044b9bf5cae45fff81fab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17651218ede9480ba42d2da67a566876":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e38195760986445fb0f5ffb3f2262342","max":371391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cfc9308637f498aaac55ae8b6b15f3a","value":371391}},"1a47fec2090b4ec29993fc2c12ea2da2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c22977e74784b1b90d41bd3c0008c70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a96e2e1b8914c988475d0d1b92b2ba0","placeholder":"​","style":"IPY_MODEL_1c4583ef08f04c1db769f8c52624877b","value":" 352M/352M [00:21\u0026lt;00:00, 17.2MB/s]"}},"1c4583ef08f04c1db769f8c52624877b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e1af957f86e4cd4a8ef098d890ab271":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2067ab2e398742eeaab036367d2db46a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"207d12a144fd4b27933a9a5b040e1b71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"22e495c133b94ef2bc86100c97b11a16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9192fdbaa4c840119106b61f3bddb39b","placeholder":"​","style":"IPY_MODEL_9983852e3b384c219b58bb8edf72b7ad","value":"Downloading vocab.txt: 100%"}},"29a78b25cfa1454ba4589b299499878c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22e495c133b94ef2bc86100c97b11a16","IPY_MODEL_3076da976d02478d8830f4f93316307b","IPY_MODEL_0dccde57f844447c83353d39c227e920"],"layout":"IPY_MODEL_70f53a4ae2f848eca5c136f57abdea09"}},"2a19939f932f45999c4573dba944f3f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bbfca0a7d8d4fc7a91cf45b3452cffc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cfc9308637f498aaac55ae8b6b15f3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f332cdea0da4911b5f7149ef6344587":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd6327456954420cb4abc6192218e373","placeholder":"​","style":"IPY_MODEL_fc7499e77dba4952900cc62fa0eeef6d","value":"Downloading special_tokens_map.json: 100%"}},"2ff6538353524518a7a7f404c752902e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3076da976d02478d8830f4f93316307b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3247e10cd74d5489bc3dd56a6f0979","max":69777,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7569c527d834534aa2c2339990bd5ad","value":69777}},"33530bbd74e14ec6afacc42886c9a794":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3407fe008aa84bcb9073525cd588489b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ff6538353524518a7a7f404c752902e","placeholder":"​","style":"IPY_MODEL_0df6ae9ad14044b9bf5cae45fff81fab","value":"Downloading tokenizer_78b3253a26.model: 100%"}},"368f59333e034f6ca485381a835cfec8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_865b740e56a24db9aa934d0396f01e8b","placeholder":"​","style":"IPY_MODEL_e3ca452566ab491087f92fce175bd5ba","value":"Downloading tokenizer_config.json: 100%"}},"3a4efb143f2f4a5e9ab27933cb6aee63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a565419bf9b43f095657e2f173dce62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b02abca7f4f4728b67b6ec9ec3271d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3eb88c11bc4c4efa86603cd847e45a90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44f5781d873e4736a0a10e768149dc6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47aeb0c9708245ea8fc41a54f8d8bc40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d297720b4d942bf96f3a6741f4b4ea3","placeholder":"​","style":"IPY_MODEL_33530bbd74e14ec6afacc42886c9a794","value":" 596/596 [00:00\u0026lt;00:00, 19.4kB/s]"}},"491987af6ae744fdb0a9bb9ffd67ead5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f1301c452f34a509764d94b7caff945":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f332cdea0da4911b5f7149ef6344587","IPY_MODEL_073267495dec4b12b1884505b8a62dd8","IPY_MODEL_da37a1ca87ef4ed6ab2be9d9e492485f"],"layout":"IPY_MODEL_d4b688acf5904ecaa156b9ecbe859434"}},"4f3247e10cd74d5489bc3dd56a6f0979":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5435abec2d6f4136971d50df66ae878f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5512d0d562f941fbaaaa962be5e53215","max":369009432,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8968cf77376f492e9d3ef6bd34f82f81","value":369009432}},"5512d0d562f941fbaaaa962be5e53215":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a96e2e1b8914c988475d0d1b92b2ba0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d297720b4d942bf96f3a6741f4b4ea3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70f53a4ae2f848eca5c136f57abdea09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c2e589312d423b9670d5370fc59650":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"865b740e56a24db9aa934d0396f01e8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8968cf77376f492e9d3ef6bd34f82f81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d8fe0b92bf74fedba89ab6e8e3acd99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9192fdbaa4c840119106b61f3bddb39b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9983852e3b384c219b58bb8edf72b7ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3dc4594bf21415b9b0cc63e6474a238":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d67fa0a86412494cbc5776e505a18025","IPY_MODEL_5435abec2d6f4136971d50df66ae878f","IPY_MODEL_1c22977e74784b1b90d41bd3c0008c70"],"layout":"IPY_MODEL_8d8fe0b92bf74fedba89ab6e8e3acd99"}},"aa299d63936c470baab2cacaf9345a16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6e39c9dfad2450b91469d10eaaa1a1d","placeholder":"​","style":"IPY_MODEL_1a47fec2090b4ec29993fc2c12ea2da2","value":" 245/245 [00:00\u0026lt;00:00, 5.83kB/s]"}},"ad291f35060b440c825598f39f883d82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af0f3ff5a21c430ba02184d269e01260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01360230d6494f7db959660fc7cfcbbe","IPY_MODEL_e1720189fdb34f828c92b9c063c84e38","IPY_MODEL_47aeb0c9708245ea8fc41a54f8d8bc40"],"layout":"IPY_MODEL_e9310a61854445d39b06c42245498bfd"}},"bb7cf85a1c764cc8b191824045d9801c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7df33d9d9cd4b30804fb735caac8aa7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c904d933658a4412a0c8e69ef6aa5ad1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd9c174d4eb14487a5bcfcb4ae6a5100":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_368f59333e034f6ca485381a835cfec8","IPY_MODEL_ea2e0e2ce84f4f57aa480f74344400c0","IPY_MODEL_aa299d63936c470baab2cacaf9345a16"],"layout":"IPY_MODEL_c904d933658a4412a0c8e69ef6aa5ad1"}},"d1abf3c0254d4d0d984f8dd89ba816ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4b688acf5904ecaa156b9ecbe859434":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d67fa0a86412494cbc5776e505a18025":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44f5781d873e4736a0a10e768149dc6a","placeholder":"​","style":"IPY_MODEL_2a19939f932f45999c4573dba944f3f1","value":"Downloading tf_model.h5: 100%"}},"d7569c527d834534aa2c2339990bd5ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da37a1ca87ef4ed6ab2be9d9e492485f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad291f35060b440c825598f39f883d82","placeholder":"​","style":"IPY_MODEL_491987af6ae744fdb0a9bb9ffd67ead5","value":" 112/112 [00:00\u0026lt;00:00, 4.29kB/s]"}},"e1720189fdb34f828c92b9c063c84e38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a4efb143f2f4a5e9ab27933cb6aee63","max":596,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1abf3c0254d4d0d984f8dd89ba816ea","value":596}},"e38195760986445fb0f5ffb3f2262342":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3ca452566ab491087f92fce175bd5ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6e39c9dfad2450b91469d10eaaa1a1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9310a61854445d39b06c42245498bfd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea2e0e2ce84f4f57aa480f74344400c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bbfca0a7d8d4fc7a91cf45b3452cffc","max":245,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2067ab2e398742eeaab036367d2db46a","value":245}},"fc7499e77dba4952900cc62fa0eeef6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcc0301a22a34ebfa30c3cf46025e819":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3407fe008aa84bcb9073525cd588489b","IPY_MODEL_17651218ede9480ba42d2da67a566876","IPY_MODEL_0851d922ebf74839be2e3983b52ed7a9"],"layout":"IPY_MODEL_84c2e589312d423b9670d5370fc59650"}},"fd6327456954420cb4abc6192218e373":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fecf7a694b144afb80b5001e4056c139":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}